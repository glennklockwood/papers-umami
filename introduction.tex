\section{Introduction} \label{sec:introduction}

The stratification of performance and capacity in storage technology is motivating the design of increasingly complex parallel storage systems architectures.
Leadership-class systems are now being deployed with flash-based burst buffers~\cite{Henseler2016} that provide even higher performance than disk-based scratch file systems~\cite{Bhimji2016}.
However, this performance comes at the cost of increasing complexity, making I/O performance analysis increasingly difficult.
%Although designed to provide optimal performance and capacity on an economic basis, this increasing number of interoperating components also complicates the task of understanding I/O performance.

The current state of practice is to monitor each component in the I/O stack separately, often resulting in telemetric data that are not obviously compatible.
%However, these components approach I/O from different perspectives, often resulting in component-level monitoring data that are not obviously compatible.
For example, server-side monitoring tools such as LMT~\cite{lmt} measure a limited number of metrics over time to achieve low overhead, while application-level profiling tools such as Darshan~\cite{carns200924} track many metrics that are summarized on a per-job basis.
% Data types representing the same logical quantity, such as data written, may also be expressed in different units such as bytes, pages, and blocks, and these units of data may also be transformed by aggregation, coalescing, and caching as they traverse the I/O stack.
At present, the gaps of information resulting from these incompatibilities are filled by expert institutional knowledge and intuition.

Absent this expert knowledge though, a principal challenge in understanding I/O performance is knowing how to gauge the performance of an application within a broader context to answer the question: 
does the I/O performance of a given job meet expectations given the capabilities of the system and the nature of the access pattern?
Relying on intuition to form a common context for different sources of I/O data to 
answer this question is not sustainable as I/O subsystems continue to grow in size and complexity.
Thus, it is becoming critical to systematically integrate data across all components to present a coherent, holistic view of the I/O subsystem to clarify the inter-dependent behavior.

To demonstrate the insights possible through such a holistic approach, we have conducted a benchmarking study of several I/O-intensive applications on two architecturally distinct production HPC systems over the course of a month.  Drawing on data already being collected on those systems, we then 
present the analysis of data integrated from file system servers, application-level profiling, and other system-level components.
By presenting how these metrics vary over the one-month experiment in a unified monitoring and metrics interface (UMAMI), this holistic approach is able to differentiate general performance expectations for different I/O motifs (analogous to the climate of the I/O system) from transient effects (analogous to the weather of the I/O system).
We use this notion of the \emph{I/O climate} to encompass the characteristics of storage components, their age and capacity, and the way they generally respond to a specific workload.
Complementary to the I/O climate, the \emph{I/O weather} is determined by transitory state of the job scheduler load, I/O contention, and short-term failure events.

%We show how TOKIO can contextualize I/O performance variation by using it to
%analyze a month-long interval of formalized I/O regression benchmarking on
%two major supercomputing facilities.
%We demonstrate a universal metrics and measurements interface (TOKIO-UMAMI) that quickly classifies a job's I/O performance as being within the expected variation of the file system climate, or if it reflects an extreme file system weather event. 
%Finally, we show how the TOKIO framework can be applied to bridge the gap of expert knowledge by identifying common sources of I/O performance variation.

The primary contributions of this work are as follows:
\begin{itemize}[leftmargin=*]
% \item We describe a framework for holistic instrumentation of I/O subsystems that is generalizable across platforms
\item We demonstrate an effective way to integrate the data from existing component-level tools available on NERSC's Edison and ALCF's Mira systems, along with a month-long automated I/O benchmarking effort, to demonstrate novel insights into performance variation.
\item We show that I/O performance is affected by both intrinsic application characteristics and extrinsic storage system factors.
Contention with other I/O workloads for storage system bandwidth is not the only factor that affects I/O performance, and
we highlight cases where metadata contention and storage capacity both dramatically impact performance.
\item We show that there is no single monitoring metric that predicts I/O performance
universally across HPC platforms; the most highly correlated metrics depend on system architecture, configuration parameters, workload characteristics, and system health.
\end{itemize}
