{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "TOKIO Dashboard Prototype"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "matplotlib.rcParams.update({'font.size': 18})\n",
      "import matplotlib.gridspec\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas\n",
      "import numpy as np\n",
      "import scipy\n",
      "import scipy.stats as stats\n",
      "import json\n",
      "import datetime\n",
      "import time\n",
      "import textwrap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load and refine data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "### Relative path to the repository's root directory\n",
      "_REPO_BASE_DIR = os.path.join('..', '..')\n",
      "\n",
      "### Translates cryptic counter names into something suitable for labeling plots\n",
      "counter_labels = json.load(open(os.path.join(_REPO_BASE_DIR, 'scripts', 'counter_labels.json'), 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_edison = pandas.DataFrame.from_csv(os.path.join(_REPO_BASE_DIR,\n",
      "                                                   'data',\n",
      "                                                   'dat',\n",
      "                                                   'tokio-lustre',\n",
      "                                                   'edison-abc-stats_2-14_3-23.csv')).dropna()\n",
      "df_edison['system'] = \"edison\"\n",
      "df_edison['darshan_rw'] = [ 'write' if x == 1 else 'read' for x in df_edison['darshan_write_mode?'] ]\n",
      "df_edison['darshan_file_mode'] = [ 'shared' if x in ['H5Part','MPIIO'] else 'fpp' for x in df_edison['darshan_api'] ]\n",
      "df_edison.rename(columns={'lmt_bytes_covered': 'coverage_factor'}, inplace=True)\n",
      "\n",
      "\n",
      "df_mira = pandas.DataFrame.from_csv(os.path.join(_REPO_BASE_DIR,\n",
      "                                                'data',\n",
      "                                                'dat',\n",
      "                                                'tokio-gpfs',\n",
      "                                                'alcf-abc-stats_2-25_3-19.dat')).dropna()\n",
      "rename_dict = { '# platform': \"system\" }\n",
      "for key in df_mira.keys():\n",
      "    if key == 'file_sys':\n",
      "        rename_dict[key] = 'darshan_file_system'\n",
      "    elif key not in rename_dict and not key.startswith('ggio_'):\n",
      "        rename_dict[key] = 'darshan_' + key\n",
      "df_mira.rename(columns=rename_dict, inplace=True)\n",
      "df_mira['darshan_file_mode'] = [ 'shared' if x in ['H5Part','MPIIO'] else 'fpp' for x in df_mira['darshan_api'] ]\n",
      "df_mira['coverage_factor'] = df_mira['darshan_total_bytes'] / (df_mira['ggio_bytes_read'] + df_mira['ggio_bytes_written'])\n",
      "\n",
      "df = pandas.concat([df_edison, df_mira])\n",
      "\n",
      "### Drop all records that are simply missing data\n",
      "df.drop(df.index[df['darshan_app'] == 'UNKNOWN'], inplace=True)\n",
      "\n",
      "### Drop data with obviously faulty coverage factors\n",
      "df.drop(df.index[df['coverage_factor'] > 1.2], inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define the dashboard view\n",
      "\n",
      "Decide what to display on the dashboard by subselecting a specific view from the loaded data via `df_plot` and then populating the `row_plots` list with only those variables we want to display."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Specify the type of job we're going to track on the dashboard\n",
      "filter_list = [ (df['darshan_app'] == \"HACC-IO\"),\n",
      "                (df[\"darshan_write_mode?\"] == 1),\n",
      "                (df['darshan_file_system'] == \"scratch2\"),\n",
      "                (df['darshan_end_time'] >= time.mktime(datetime.date(2017,  2, 25).timetuple())),\n",
      "                (df['darshan_end_time'] <= time.mktime(datetime.date(2017,  3,  4).timetuple())),\n",
      "            ]\n",
      "\n",
      "net_filter = [ True for i in range(len(df.index))]\n",
      "for idx, condition in enumerate(filter_list):\n",
      "    ct = len( [ x for x in net_filter if x ] )\n",
      "    net_filter &= condition\n",
      "    print \"Dropped %d rows after filter #%d\" % ((ct - len( [ x for x in net_filter if x ] )), idx)\n",
      "    \n",
      "df_plot = df[net_filter].copy()\n",
      "print \"%d rows will be included in UMAMI\" % len(df_plot.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Then specify the variables which wish to display on the\n",
      "### dashboard.  Keyed by variables to display, and the values\n",
      "### indicate if a high value is good\n",
      "row_plots = [\n",
      "    ('darshan_agg_perf_by_slowest_gibs', True),\n",
      "    ('coverage_factor',                  True),\n",
      "    ('lmt_mds_ave',                      False),\n",
      "    ('lmt_ops_opencloses',               False),\n",
      "    ('lmt_oss_ave',                      False),\n",
      "    ('ost_avg_pct',                      False),\n",
      "    ('ost_bad_pct',                      False),\n",
      "    ('job_max_radius',                   False),\n",
      "    ('job_concurrent_jobs',              False),\n",
      "]\n",
      "\n",
      "### Some rendering parameters for the dashboard itself\n",
      "_DASHBOARD_FONT_SIZE = 12\n",
      "_DASHBOARD_LINE_WIDTH = 1\n",
      "_DASHBOARD_HIGHLIGHT_COLORS = [ '#DA0017', '#FD6A07', '#40A43A', '#2C69A9' ]\n",
      "_DASHBOARD_LINE_COLOR = '#853692'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once the correct input view and outputs are defined, make a copy of the data that we manipulate to get the data into a plottable form."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_plot['darshan_agg_perf_by_slowest_gibs'] = df_plot['darshan_agg_perf_by_slowest'] / 1024.0\n",
      "# df_plot['darshan_end_time_dt'] = [ datetime.datetime.fromtimestamp(x) for x in df_plot['darshan_end_time'].values ]\n",
      "# df_plot['darshan_start_time_dt'] = [ datetime.datetime.fromtimestamp(x) for x in df_plot['darshan_start_time'].values ]\n",
      "\n",
      "### we need to make this more portable across LMT and GGIOSTAT :(\n",
      "df_plot['lmt_ops_opencloses'] = df_plot['lmt_ops_opens'] + df_plot['lmt_ops_closes']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Can also just add up all the MDS ops (of interest).\n",
      "### Even though they are not weighted evenly in terms\n",
      "### of cost on MDS, this is a rough approximation of\n",
      "### activity since metadata rates are also bursty and\n",
      "### probably don't overlap often.\n",
      "for i in df_plot.keys():\n",
      "    if \"_ops_\" in i:\n",
      "        if \"lmt_ops_total\" in df_plot:\n",
      "            df_plot['lmt_ops_total'] += df_plot[i]\n",
      "        else:\n",
      "            df_plot['lmt_ops_total'] = df_plot[i]\n",
      "counter_labels['lmt_ops_total'] = \"Total metadata ops on MDS\"\n",
      "counter_labels['lmt_ops_opencloses'] = \"Total open+close ops on MDS\"\n",
      "\n",
      "### Scale op counts to make them plottable:\n",
      "for i in df_plot.keys():\n",
      "    if \"_ops_\" in i:\n",
      "        max_val = df_plot[i].max()\n",
      "        if max_val > 2e9:\n",
      "            df_plot[i] = df_plot[i] / 1e9\n",
      "            counter_labels[i] += \" (GOps)\"\n",
      "        elif max_val > 2e6:\n",
      "            df_plot[i] = df_plot[i] / 1e6\n",
      "            counter_labels[i] += \" (MOps)\"\n",
      "        elif max_val > 2e3:\n",
      "            df_plot[i] = df_plot[i] / 1e3\n",
      "            counter_labels[i] += \" (KOps)\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now actually generate the dashboard diagram."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "fig.set_size_inches(6,12)\n",
      "\n",
      "### Required to adjust the column widths of our figure (width_ratios)\n",
      "gridspec = matplotlib.gridspec.GridSpec(len(row_plots), 2, width_ratios=[4,1])\n",
      "\n",
      "last_ax_ts = None\n",
      "for idx, (plot_variable, big_is_good) in enumerate(row_plots):\n",
      "    def dt64todatetime(dt64):\n",
      "        \"\"\"\n",
      "        the dataframe stores datetimes as np.datetime64,\n",
      "        which is expressed in nanoseconds (1e9 seconds).  To\n",
      "        convert this to a datetime.datetime object which we\n",
      "        can transform in matplotlib, some amount of\n",
      "        gymnastics is required.\n",
      "        \"\"\"\n",
      "        return datetime.datetime.fromtimestamp(dt64.astype(int) * 1e-9)\n",
      "    \n",
      "    ### Cast all pandas times (numpy.datetime64) into Python datetimes\n",
      "    x = [ datetime.datetime.fromtimestamp(x) for x in df_plot['darshan_end_time'].values ]\n",
      "    y = df_plot[plot_variable].values\n",
      "\n",
      "    ### first plot the timeseries of the given variable\n",
      "    ax_ts = fig.add_subplot(gridspec[2*idx])\n",
      "    ax_ts.plot(x, y,\n",
      "               linestyle='-',\n",
      "               marker='x',\n",
      "               linewidth=_DASHBOARD_LINE_WIDTH * 1.0,\n",
      "               color=_DASHBOARD_LINE_COLOR)\n",
      "\n",
      "    # textwrap.wrap inserts line breaks into each label\n",
      "    ax_ts.set_ylabel('\\n'.join(textwrap.wrap(\n",
      "                        text=counter_labels.get(plot_variable, plot_variable),\n",
      "                        width=15)),\n",
      "                        fontsize=_DASHBOARD_FONT_SIZE,\n",
      "                        rotation=0,\n",
      "                        horizontalalignment='right',\n",
      "                        verticalalignment='center'\n",
      "                    )\n",
      "    ax_ts.grid()\n",
      "\n",
      "    # blank out the labels for all subplots except the bottom-most one\n",
      "    if idx != len(row_plots) - 1:\n",
      "        ax_ts.set_xticklabels([])\n",
      "    else:\n",
      "        last_ax_ts = ax_ts\n",
      "        # resize and rotate the labels for the timeseries plot\n",
      "        for tick in ax_ts.xaxis.get_major_ticks():\n",
      "            tick.label.set_fontsize(_DASHBOARD_FONT_SIZE) \n",
      "            tick.label.set_rotation(45)\n",
      "\n",
      "    # also adjust the font size for the y labels\n",
      "    for tick in ax_ts.yaxis.get_major_ticks():\n",
      "        tick.label.set_fontsize(_DASHBOARD_FONT_SIZE)\n",
      "\n",
      "    ### then plot the boxplot summary of the given variable\n",
      "    ax_box = fig.add_subplot(gridspec[2*idx+1])\n",
      "    boxp = ax_box.boxplot(y[0:-1], ### note: do not include last measurement in boxplot\n",
      "                   widths=0.70,\n",
      "                   boxprops={'linewidth':_DASHBOARD_LINE_WIDTH},\n",
      "                   medianprops={'linewidth':_DASHBOARD_LINE_WIDTH},\n",
      "                   whiskerprops={'linewidth':_DASHBOARD_LINE_WIDTH},\n",
      "                   capprops={'linewidth':_DASHBOARD_LINE_WIDTH},\n",
      "                   flierprops={'linewidth':_DASHBOARD_LINE_WIDTH},\n",
      "                   whis=[5,95])\n",
      "    \n",
      "    # scale the extents of the y ranges a little for clarity\n",
      "    ax_ts.set_ylim(map(lambda a, b: a*(1 + b), ax_ts.get_ylim(), (-0.1, 0.1)))\n",
      "    \n",
      "    # lock in the y range to match the timeseries plot, just in case\n",
      "    ax_box.set_ylim(ax_ts.get_ylim())\n",
      "\n",
      "    # determine the color of our highlights based on quartile\n",
      "    percentiles = [ np.percentile(y[0:-1], percentile) for percentile in 25, 50, 75, 100 ]\n",
      "    for color_index, percentile in enumerate(percentiles):\n",
      "        if y[-1] <= percentile:\n",
      "            break\n",
      "    if big_is_good:\n",
      "        highlight_color = _DASHBOARD_HIGHLIGHT_COLORS[color_index]\n",
      "    else:\n",
      "        highlight_color = _DASHBOARD_HIGHLIGHT_COLORS[(1+color_index)*-1]\n",
      "                                        \n",
      "    # highlight the latest measurement on the timeseries plot\n",
      "    x_last = matplotlib.dates.date2num(x[-1])\n",
      "    x_2nd_last = matplotlib.dates.date2num(x[-2])\n",
      "    ax_ts.plot([x_2nd_last, x_last],\n",
      "               [y[-2], y[-1]],\n",
      "               linestyle='-',\n",
      "               color=highlight_color,\n",
      "               linewidth=_DASHBOARD_LINE_WIDTH * 2.0)\n",
      "    ax_ts.plot([x_last], [y[-1]],\n",
      "               marker='*',\n",
      "               color=highlight_color,\n",
      "               markersize=15)\n",
      "\n",
      "    # where does this last data point lie on the distribution?\n",
      "    ax_box.plot([0,2], [y[-1],y[-1]], linestyle='--', color=highlight_color, linewidth=2.0, zorder=10)\n",
      "\n",
      "    # blank out all labels\n",
      "    ax_box.set_yticklabels([\"\"])\n",
      "    ax_box.set_xticklabels([\"\"])\n",
      "    ax_box.yaxis.grid()\n",
      "\n",
      "fig.subplots_adjust(hspace=0.0, wspace=0.0)\n",
      "fig.autofmt_xdate()\n",
      "last_ax_ts.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b %d'))\n",
      "\n",
      "output_file = \"umami.pdf\"\n",
      "fig.savefig(output_file, bbox_inches=\"tight\")\n",
      "print \"Saved %s\" % output_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}