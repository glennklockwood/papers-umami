#!/usr/bin/env python
# coding: utf-8

# # Statistical Analysis of TOKIO-ABC Results
# 
# This notebook performs various statistical analyses of the summary data generated by each TOKIO-ABC job.  These data are loaded from __a summary csv file__ where each row represents a single job and contains the relevant data extracted from
# 
# 1. the darshan log
# 2. the server-side I/O monitoring (Lustre LMT or GPFS GGIOSTAT)
# 3. optional system-specific monitoring including
#     - OST health info (Lustre)
#     - Concurrent job count (Slurm)
#     - Job radius (Cray XC)
#     
# This input CSV is generated at NERSC by
# 
# 1. running `utils/nersc_generate_job_summary.sh` to generate json summary records for each darshan log
# 2. running `utils/json2csv.py` to convert all jsons into a single csv file
# 
# This script is used to identify interesting patterns and correlations across jobs.  For intra-job inspection, use other analysis notebooks such as `analysis/per_ost_deep_dive.ipynb`.

# In[1]:

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
matplotlib.rcParams.update({'font.size': 18})
plt.rcParams['image.cmap'] = 'gray'
import matplotlib.gridspec
import IPython.display
import os


# In[2]:

import pandas
import numpy as np
import scipy
import scipy.stats as stats
import scipy.interpolate
import json
import datetime
import bisect
import warnings
import textwrap

def wrap(text, width=15):
    """wrapper for the wrapper"""
    return '\n'.join(textwrap.wrap(text=text,width=width))


# In[4]:

### Relative path to the repository's root directory
_REPO_BASE_DIR = os.path.join('..', '..')

### Translates cryptic counter names into something suitable for labeling plots
counter_labels = json.load(open(os.path.join(_REPO_BASE_DIR, 'scripts', 'counter_labels.json'), 'r'))

### For consistency, always plot file systems in the same order
_FILE_SYSTEM_ORDER = [ 'scratch1', 'scratch2', 'scratch3', 'mira-fs1' ]


# In[4]:

def plot_corr(df,size=20):
    """
    Function plots a graphical correlation matrix for each pair
    of columns in the dataframe.  From
    
    http://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas

    Input:
        df: pandas DataFrame
        size: vertical and horizontal size of the plot
    """
    matplotlib.rc('xtick', labelsize=20)
    matplotlib.rc('ytick', labelsize=20)
    corr = df.corr()
    fig, ax = plt.subplots(figsize=(size, size))
    ax.matshow(corr, cmap=plt.get_cmap('seismic'),
                    norm=matplotlib.colors.Normalize(vmin=-1.,vmax=1.) )
    plt.xticks(range(len(corr.columns)), corr.columns, rotation='vertical')
    plt.yticks(range(len(corr.columns)), corr.columns)
    return corr


# ## Load data

# In[5]:

### Edison
df_edison = pandas.DataFrame.from_csv(os.path.join(_REPO_BASE_DIR,
                                                   'data',
                                                   'dat',
                                                   'tokio-lustre',
                                                   'edison-abc-stats_2-14_3-23.csv')).dropna()
df_edison['darshan_rw'] = [ 'write' if x == 1 else 'read' for x in df_edison['darshan_write_mode?'] ]
df_edison['darshan_file_mode'] = [ 'shared' if x in ['H5Part','MPIIO'] else 'fpp' for x in df_edison['darshan_api'] ]
df_edison.rename(columns={'lmt_bytes_covered': 'coverage_factor'}, inplace=True)

### Mira
df_mira = pandas.DataFrame.from_csv(os.path.join(_REPO_BASE_DIR,
                                                'data',
                                                'dat',
                                                'tokio-gpfs',
                                                'alcf-abc-stats_2-25_3-19.dat')).dropna()
rename_dict = { '# platform': "system" }
for key in df_mira.keys():
    if key == 'file_sys':
        rename_dict[key] = 'darshan_file_system'
    elif key not in rename_dict and not key.startswith('ggio_'):
        rename_dict[key] = 'darshan_' + key
df_mira.rename(columns=rename_dict, inplace=True)
df_mira['darshan_file_mode'] = [ 'shared' if x in ['H5Part','MPIIO'] else 'fpp' for x in df_mira['darshan_api'] ]
df_mira['coverage_factor'] = df_mira['darshan_total_bytes'] / (df_mira['ggio_bytes_read'] + df_mira['ggio_bytes_written'])
df_mira = df_mira[df_mira['coverage_factor'] < 1.2]

### Both
df_concat = pandas.concat( (df_mira, df_edison) )


# ## Normalize Performance
# Different file systems, benchmarks, and read/write modes are capable of different peak bandwidths.  As such, we want to normalize the absolute performance (`summarize_key`) by something.  For convenience we calculate the denominator for normalization a couple of different ways (e.g., the mean, median, and max measurement).  We also limit normalization to unique combinations of variables specified by `normalization_group` below.

# Calculate the normalization factors (the denominators), then apply that factor to all of the data in the DataFrame.  These normalized data will be saved as new columns in the DataFrame.

# In[8]:

### The actual variable we want to normalize
summarize_key = 'darshan_agg_perf_by_slowest'

for df in df_edison, df_mira, df_concat:
    ### Specify which keys we want to group together before normalizing
    normalization_group = df.groupby(['darshan_app', 'darshan_file_system', 'darshan_file_mode', 'darshan_rw'])

    ### Dict to store the denominators for normalization
    normalization_data = {
        'mean':   normalization_group.darshan_agg_perf_by_slowest.mean(),
        'median': normalization_group.darshan_agg_perf_by_slowest.median(),
        'max':    normalization_group.darshan_agg_perf_by_slowest.max(),
    }

    ### Normalize every row in the DataFrame by all of our denominators
    new_cols = {}
    for func in normalization_data.keys():
        new_col_key = 'darshan_normalized_perf_by_%s' % func
        new_cols[new_col_key] = []
        for index, row in df.iterrows():
            new_cols[new_col_key].append(
                row[summarize_key] / normalization_data[func]
                                                       [row['darshan_app']]
                                                       [row['darshan_file_system']]
                                                       [row['darshan_file_mode']]
                                                       [row['darshan_rw']]
            )

    ### Also just do per-file system
    normalization_group = df.groupby('darshan_file_system')
    normalization_data = {
        'mean':   normalization_group.darshan_agg_perf_by_slowest.mean(),
        'median': normalization_group.darshan_agg_perf_by_slowest.median(),
        'max':    normalization_group.darshan_agg_perf_by_slowest.max(),
    }
    for func in normalization_data.keys():
        new_col_key = 'darshan_normalized_perf_by_fs_%s' % func
        new_cols[new_col_key] = []
        for index, row in df.iterrows():
            new_cols[new_col_key].append(
                row[summarize_key] / normalization_data[func][row['darshan_file_system']])

    ### Take our normalized data and add them as new columns
    for new_col, new_col_data in new_cols.iteritems():
        df[new_col] = new_col_data


# ## Multivariate Correlation Analysis
# `performance_key` is the variable we wish to use to represent performance.  It is typically
# 
# - `darshan_agg_perf_by_slowest`, which is the absolute performance measured by each benchmark run
# - `darshan_normalized_perf_by_max`, which is normalized by the maximum observed performance
# - `darshan_normalized_perf_by_mean`, which is normalized by the mean observed performance

# In[9]:

performance_key = 'darshan_normalized_perf_by_max'


# ### Pearson Correlation Analysis
# Pearson analysis assumes that each variable is normally distributed.  It is easier to understand, but it is not technically correct for variables that are _not_ normally distributed, which include performance.  The Spearman coefficient would be better.
# 
# At any rate, this correlation matrix is not of interest to this paper so don't bother generating it here.

# In[10]:

### make a pretty plot to flag highlights
if False:
    corr_edison = plot_corr(df_edison[
        (df_edison['darshan_file_system'] == 'scratch1') 
        | (df_edison['darshan_file_system'] == 'scratch2') 
        | (df_edison['darshan_file_system'] == 'scratch3')
    ], 10)
    corr_mira = plot_corr(df[df['darshan_file_system'] == 'mira-fs1'], 10)


# ### Numerical Correlation Analysis
# Now we repeat this correlation analysis, but this time use `scipy.stats` instead of `pandas` so that we can calculate p-values associated with each correlation.

# In[11]:

def correlation_calculation(df, analysis_func=stats.pearsonr, only_print_key=performance_key, ignore_cols=[]):
    """
    Calculate the Pearson correlation coefficient and the associated
    p-value for every permutation of counter pairs
    """
    num_cols = len(df.keys())
    results = []
    for i in range(num_cols - 1):
        i_col = df.columns[i]
        for j in range(i, num_cols):
            j_col = df.columns[j]
            try:
                coeff, pval = analysis_func(df[i_col],
                                            df[j_col])
            except TypeError: # non-numeric column
                continue
            results.append((i_col,
                            j_col,
                            coeff,
                            pval))

    sorted_results = sorted(results, key=lambda x: x[3])
    ret_results = []
    for col_name1, col_name2, coeff, pval in sorted_results:
        ### don't print trivial relationships
        if pval == 0 or pval == 1:
            continue
        ### don't print relationships with very high p-values
#       if pval > 0.05:
#           continue
        ### don't correlate data from the same source since much of it is degenerate
        if col_name1.split('_',1)[0] == col_name2.split('_',1)[0]:
            continue
        ### don't print anything except for the key of interest (if provided)
        if only_print_key is not None         and col_name1 != only_print_key         and col_name2 != only_print_key:
            continue
        print "%10.4f %10.4g %30s : %-15s" % (coeff, pval, col_name1, col_name2)
        
        ### sort the output key orders
        if col_name1 == only_print_key:
            ret_results.append((col_name1,col_name2))
        elif col_name2 == only_print_key:
            ret_results.append((col_name2,col_name1))
        else:
            ret_results.append((col_name1,col_name2) if col_name2 > col_name1 else (col_name2,col_name1))
    return ret_results


# In[12]:

print "===== Edison ====="
correlations_edison = correlation_calculation(df_edison)
print "====== Mira ======"
correlations_mira = correlation_calculation(df_mira)


# ### Scatter Plots
# To visualize these correlations, we define pairs of counters to plot against each other:

# In[13]:

scatterplots = [ 
    (performance_key, 'coverage_factor'),
    (performance_key, 'lmt_oss_ave'),
    (performance_key, 'job_concurrent_jobs'),
    (performance_key, 'ost_avg_pct'),
    (performance_key, 'ost_max_kib'),
    (performance_key, 'coverage_factor'),
    (performance_key, 'ggio_write_reqs'),
    (performance_key, 'ggio_write_reqs'),
]


# ...and then plot them:

# In[14]:

blacklist = set([
    'ost_max_id', 'ost_min_id', 'lmt_tot_zeros',
    'ost_failures_lead_secs', 'ost_fullness_lead_secs',
    'ost_max_kib', 'ost_avg_kib', 'ost_min_kib', 
    'lmt_tot_missing'
])
# for scatterplot in correlations_edison + correlations_mira:
for scatterplot in scatterplots:
    x_key = scatterplot[0]
    y_key = scatterplot[1]
    if x_key in blacklist or y_key in blacklist:
        continue
    if y_key in df_mira :
        df_plot = df_mira
        system = "Mira"
    elif y_key in df_edison:
        df_plot = df_edison
        system = "Edison"
    else:
        warnings.warn("Cannot find key %s in any data frames" % y_key)
    fig = plt.figure(figsize=(6,4))
    ax = fig.add_subplot(111)
    
    x = df_plot[x_key].values
    x_label = counter_labels.get(x_key, x_key)
    y = df_plot[y_key].values
    y_label = counter_labels.get(y_key, y_key)
#   ax.hexbin(x, y, gridsize=25, cmap='PuRd')
    ax.plot(x, y, 'o', alpha=0.5)

    ### attempt a linear fit to generate a visual aid
    m, b = np.polyfit(x, y, 1)
    ax.plot(x, m*x+b, "-")
    
    ### add window dressing to plots
#   fig.suptitle('Correlation between %s and %s' 
#                 % (x_label.split('(',1)[0].strip(),
#                    y_label.split('(',1)[0].strip()))
    ax.set_title("Coefficient=%.4f, P-value=%.2g (%s)" 
                    % sum((stats.pearsonr(x, y), (system,)), ()), fontsize=14 )
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)
    plt.grid(True)
    output_file = "scatter_%s_vs_%s.pdf" % (x_key, y_key)
    fig.savefig(output_file, bbox_inches="tight")
    print "Saved %s" % output_file


# Combine all of the interesting Mira correlations into a single plot:

# In[15]:

fig = plt.figure(figsize=(8,4))
ax = fig.add_subplot(111)

df = df_mira.sort_values(performance_key).copy()

### Job 1039807 had extremely high read ops registered for all of its benchmarks
# df = df_mira[df_mira['darshan_jobid'] != 1039807].sort_values(performance_key).copy()

# for scatterplot in correlations_mira:
for scatterplot in [
#                   (performance_key, 'ggio_bytes_written'),
#                   (performance_key, 'ggio_bytes_read'),
                    (performance_key, 'ggio_write_reqs'),
                    (performance_key, 'ggio_read_reqs'),
                   ]:
    x_key = scatterplot[0]
    y_key = scatterplot[1]
    if x_key in blacklist or y_key in blacklist:
        continue
    system = "Mira"
    
    x = df[x_key].values
    y = df[y_key].values / df[y_key].max()
    corr = stats.pearsonr(x, y)
    print counter_labels.get(y_key, y_key), corr[0], corr[1]
    if corr[1] < 0.05:
        points = ax.plot(x, y,
                         'o',
                         alpha=0.4,
                         markersize=6.0,
                         label="%s" % (counter_labels.get(y_key, y_key))
                        )
    else:
        points = ax.plot(x, y,
                         'x',
                         alpha=1.0,
                         markersize=8.0,
                         markeredgewidth=2.0,
                         label="%s" % (counter_labels.get(y_key, y_key))
                        )


        
    if corr[1] < 0.05:
        ### attempt a linear fit to generate a visual aid
        m, b = np.polyfit(x, y, 1)
        ax.plot(x, m*x+b,
                "-",
               color=points[0].get_color())
    
ax.set_xlabel(counter_labels.get(x_key, x_key))
ax.set_ylabel("Fraction Peak Ops")
ax.legend()
plt.grid(True)
output_file = "scatter_mira_ops.pdf"
fig.savefig(output_file, bbox_inches="tight")
print "Saved %s" % output_file


# In[16]:

for key in 'ggio_bytes_written', 'ggio_bytes_read', 'ggio_write_reqs', 'ggio_read_reqs':
    if key.endswith('_reqs'):
        print "%10d Kops %s" % (df_plot[key].max() / 10.0**3, key, )
    else:
        print "%10d GiB  %s" % (df_plot[key].max() / 2.0**30, key, )


# Plot the correlation between coverage factor and performance for each file system separately

# In[17]:

# for scatterplot in correlations_mira:
for idx, fs in enumerate(_FILE_SYSTEM_ORDER):
    fig = plt.figure(figsize=(8,6))
    ax = fig.add_subplot(111)
    x_key = performance_key
    y_key = 'coverage_factor'
    if fs.startswith('mira') :
        df_plot = df_mira.sort_values(performance_key)
        system = "Mira"
    elif fs.startswith('scratch'):
        df_plot = df_edison.sort_values(performance_key)
        system = "Edison"
    else:
        warnings.warn("Cannot find key %s in any data frames" % y_key)
    df_plot = df_plot[df_plot['darshan_file_system'] == fs]
    
    x = df_plot[x_key].values
    y = df_plot[y_key].values
    corr = stats.pearsonr(x, y)
    label = "%s (corr=%.2f, p-val=%4.2g, n=%d)" % (fs, corr[0], corr[1], len(df_plot))
    points = ax.plot(x, y,
                     'o', 
                     alpha=0.75,
                     markersize=4.0)

    ### attempt a linear fit to generate a visual aid
    m, b = np.polyfit(x, y, 1)
    ax.plot(x, m*x+b,
            "-",
           color=points[0].get_color())
    
    ### make the plot pretty
    ax.set_xlim([0.0,2.0 if 'mean' in x_key else 1.0])
    ax.set_ylabel("Coverage Factor")
    ax.set_xlabel(counter_labels[performance_key])
    ax.set_title(label, fontsize=14)
    plt.grid(True)
    output_file = "scatter_perf-vs-cf_%s.pdf" % fs
    fig.savefig(output_file, bbox_inches="tight")
    print "Saved %s" % output_file
    fig.savefig(output_file.replace('pdf', 'png'), bbox_inches="tight")
    print "Saved %s" % output_file
    df_save = pandas.DataFrame({"Performance Relative to Mean": x,
                                "Coverage Factor": y}).to_csv(output_file.replace('pdf', 'csv'))
    print "Saved", output_file.replace('pdf', 'csv')


# ### Strategic Scatter Plots
# 
# Now instead of just generating a bunch of scatter plots that show interesting correlations, let's plot some to illustrate specific relationships.
# 
# First build a dataframe with normalized data so that we can fairly compare Mira and Edison if desired:

# In[18]:

### Juggle these for the purposes of correlating performance
old_performance_key = performance_key
performance_key = 'darshan_normalized_perf_by_max'


# In[19]:

df_plot_e = df_edison[['darshan_file_system', 'darshan_app', 'darshan_rw', performance_key]].copy()
df_plot_e['opens'] = df_edison['lmt_ops_opens']
df_plot_e['closes'] = df_edison['lmt_ops_closes']
df_plot_e['opens+closes'] = df_plot_e['opens'] + df_plot_e['closes']
df_plot_e['opens+closes_normalized'] = df_plot_e['opens+closes'] / df_plot_e['opens+closes'].max()

df_plot_m = df_mira[['darshan_file_system', 'darshan_app', 'darshan_rw', performance_key]].copy()
df_plot_m['opens'] = df_mira['ggio_opens']
df_plot_m['closes'] = df_mira['ggio_closes']
df_plot_m['opens+closes'] = df_plot_m['opens'] + df_plot_m['closes']
df_plot_m['opens+closes_normalized'] = df_plot_m['opens+closes'] / df_plot_m['opens+closes'].max()
df_plot_m['readops'] = df_mira['ggio_read_reqs']
df_plot_m['writeops'] = df_mira['ggio_write_reqs']
df_plot_m['iops'] = df_plot_m['readops'] + df_plot_m['writeops']
df_plot_m['iops_normalized'] = df_plot_m['iops'] / df_plot_m['iops'].max()

df_plot = pandas.concat([df_plot_e, df_plot_m], axis=0)


# Plot the relationship between performance and open+close rates.  Our expectation is that Mira is more sensitive to this since metadata and data are serviced by the same GPFS servers; by comparison, Edison's Lustre file systems have discrete MDSes which should decouple data performance from metadata performance.
# 
# That said, there is a non-causational relationship between metadata rates and data rates on Edison by virtue of the fact that lots of metadata implies that a lot of I/O (perhaps small transactions) is also happening on those file systems.  Because we aren't capturing IOPS rates on Lustre, we have no way to tell what the combined bandwidth and IOPS loads on Lustre are.

# In[20]:

_USE_LOG = False
fig = plt.figure(figsize=(8,6))
ax = fig.add_subplot(111)

criteria = {
    'Edison': df_plot['darshan_file_system'] == 'scratch1', # != 'mira-fs1',
    'Mira': df_plot['darshan_file_system'] == 'mira-fs1',
}
for label, criterion in criteria.iteritems():
    x = df_plot[criterion]         .sort_values(performance_key)[performance_key].values

    ### normalize to only the data we're looking at on Edison
    y = df_plot[criterion]         .sort_values(performance_key)['opens+closes']         / df_plot[criterion]['opens+closes'].max()

    if label == 'Edison':
        markersize=2.0
        alpha=0.75
    else:
        markersize=8.0
        alpha=0.50
    ax.plot(x, y, ls="", marker='o', alpha=alpha, label=label, markersize=markersize)
    
    if not _USE_LOG:
        ### attempt a linear fit to generate a visual aid
        m, b = np.polyfit(x, y, 1)
        ax.plot(x, m*x+b, "-", label=label, linewidth=4.0)
    print "Coefficient=%.4f, P-value=%.2g (%s)" % sum((stats.pearsonr(x, y), (label,)), ())

ax.set_xlabel(wrap("Fraction Peak Performance (Application)", 30))
ax.set_ylabel(wrap("Fraction Peak Opens+Closes (Server)", 30))
if _USE_LOG:
    ax.set_yscale("log")
ax.legend()
ax.grid()
del _USE_LOG


# On Mira, is application performance related to IOPS or bandwidth load?

# In[21]:

_USE_LOG = False
fig = plt.figure(figsize=(8,6))
ax = fig.add_subplot(111)

criteria = {
#    'Edison': df_plot['darshan_file_system'] == 'scratch3', # != 'mira-fs1',
    'Mira read': ((df_plot['darshan_file_system'] == 'mira-fs1') & (df_plot['darshan_rw'] == 'read')),
    'Mira write': ((df_plot['darshan_file_system'] == 'mira-fs1') & (df_plot['darshan_rw'] == 'write')),
}
for label, criterion in criteria.iteritems():
    x = df_plot[criterion].sort_values(performance_key)[performance_key].values
    y = df_plot[criterion].sort_values(performance_key)['iops_normalized']
    if label == 'Edison':
        markersize=2.0
        alpha=0.75
    else:
        markersize=8.0
        alpha=0.50
    ax.plot(x, y, ls="", marker='o', alpha=alpha, label=label, markersize=markersize)
    
    if not _USE_LOG:
        ### attempt a linear fit to generate a visual aid
        m, b = np.polyfit(x, y, 1)
        ax.plot(x, m*x+b, "-", label=label, linewidth=4.0)
    print "Coefficient=%.4f, P-value=%.2g (%s)" % sum((stats.pearsonr(x, y), (label,)), ())

ax.set_xlabel(wrap("Fraction Peak Performance (Application)", 30))
ax.set_ylabel(wrap("Fraction Peak IOPS (Server)", 30))
if _USE_LOG:
    ax.set_yscale("log")
ax.legend()
ax.grid()
ax.set_title(wrap("No compelling relationship between IOPS and bandwidth on GPFS", 30),
             fontsize=14,
             position=(0.05, 0.4),
             horizontalalignment='left',
             backgroundcolor='white',
            )
del _USE_LOG


# What about everything else on Mira?  What is affecting Mira's performance?

# In[22]:

_USE_LOG = False
fig = plt.figure(figsize=(8,6))
ax = fig.add_subplot(111)

criteria = {
#    'Edison': df_plot['darshan_file_system'] == 'scratch3', # != 'mira-fs1',
    'Mira read': ((df_plot['darshan_file_system'] == 'mira-fs1') & (df_plot['darshan_rw'] == 'read')),
    'Mira write': ((df_plot['darshan_file_system'] == 'mira-fs1') & (df_plot['darshan_rw'] == 'write')),
}
for label, criterion in criteria.iteritems():
    x = df_plot[criterion].sort_values(performance_key)[performance_key].values
    y = df_plot[criterion].sort_values(performance_key)['iops_normalized']
    if label == 'Edison':
        markersize=2.0
        alpha=0.75
    else:
        markersize=8.0
        alpha=0.50
    ax.plot(x, y, ls="", marker='o', alpha=alpha, label=label, markersize=markersize)
    
    if not _USE_LOG:
        ### attempt a linear fit to generate a visual aid
        m, b = np.polyfit(x, y, 1)
        ax.plot(x, m*x+b, "-", label=label, linewidth=4.0)
    print "Coefficient=%.4f, P-value=%.2g (%s)" % sum((stats.pearsonr(x, y), (label,)), ())

ax.set_xlabel(wrap("Fraction Peak Performance (Application)", 30))
ax.set_ylabel(wrap("Fraction Peak IOPS (Server)", 30))
if _USE_LOG:
    ax.set_yscale("log")
ax.legend()
ax.grid()
ax.set_title(wrap("No compelling relationship between IOPS and bandwidth on GPFS", 30),
             fontsize=14,
             position=(0.05, 0.4),
             horizontalalignment='left',
             backgroundcolor='white',
            )
del _USE_LOG


# In[23]:

performance_key = old_performance_key


# ## Distribution of each benchmark type

# Following cell defines which variable we wish to aggregate into boxplots and a few plotting parameters that depend on our choice of variable.

# In[24]:

boxplot_settings = {
    'fontsize': 15,
    'darshan_normalized_perf_by_fs_max': {
        'output_file': "perf-boxplots-per-fs.pdf",
        'ylabel': "Fraction of Peak\nFile System Performance",
        'title_pos': [ 
            {'x': 0.97, 'y': 0.80, 'horizontalalignment': 'right', 'fontsize': 14},
            {'x': 0.04, 'y': 0.02, 'horizontalalignment': 'left', 'fontsize': 14}]
    },
    'darshan_normalized_perf_by_max': {
        'output_file': "perf-boxplots.pdf",
        'ylabel': "Fraction of Peak\nPer-Benchmark Performance",
        'title_pos': [ 
            {'x': 0.04, 'y': 0.02, 'horizontalalignment': 'left', 'fontsize': 14},
            {'x': 0.04, 'y': 0.02, 'horizontalalignment': 'left', 'fontsize': 14}]
    },
}


# We plot two sets of boxplots based on the normalization denominator:
# 
# 1. normalized by the maximum without any grouping (other than file system)
# 2. normalized by the maximum of each unique combination of app-read/write-filemode
# 
# The idea is to show that
# 
# 1. performance variation varies across different file systems and different applications
# 2. even within an application, the magnitude of performance variation varies with file system

# In[25]:

for plot_variable in performance_key, performance_key.replace('_by_', '_by_fs_'):
    fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True)
    fig.set_size_inches(8,6)
    boxplot_group_by = [ 'darshan_file_mode', 'darshan_rw', 'darshan_app' ]
    for idx, fs in enumerate(_FILE_SYSTEM_ORDER):
        icol = idx / 2
        irow = idx % 2
        ax = axes[irow, icol]
        df_concat.loc[df_concat["darshan_file_system"] == fs]        .boxplot(
            column=[plot_variable],
            by=boxplot_group_by,
            ax=axes[irow, icol],
            medianprops={'linewidth':2 },
            widths=0.75,
            whis=[5,95])

        settings = boxplot_settings[plot_variable]['title_pos'][irow]
        title = ax.set_title(fs, **(settings))
        title.set_bbox({'color': 'white', 'alpha': 0.5})
        ax.set_xlabel("")
        ax.set_ylabel("")
        ax.xaxis.grid(True)

        ### relabel the x axis labels
        new_labels = []
        for axis_label in ax.get_xticklabels():
            current_label = axis_label.get_text()
            axis_label.set_rotation(90)
            if "IOR" in current_label:
                if "shared" in current_label:
                    new_label = "IOR/shared"
                else:
                    new_label = "IOR/fpp"
            elif 'BD-CATS' in current_label:
                new_label = "BD-CATS"
            else:
                new_label = current_label.split(',')[2].strip(')').strip().split('-')[0]
            if 'write' in current_label:
                new_label += " Write"
            else:
                new_label += " Read"
            new_labels.append(new_label)

        ### set x tick labels for only the bottom row
        if irow == 0:
            ax.set_xticklabels([])
        else:
            ax.set_xticklabels(new_labels,
                               fontsize=boxplot_settings['fontsize'])

        ax.yaxis.set_ticks([0.0, 1.0])
        ax.set_ylim([-0.1, 1.1])
        for ytick in ax.yaxis.get_major_ticks():
            ytick.label.set_fontsize(boxplot_settings['fontsize'])

        
    fig.suptitle("")
    # fig.text(0.5, -0.4, 'common X', ha='center')
    fig.text(0.0, 0.5,
             boxplot_settings[plot_variable]['ylabel'],
             verticalalignment='center',
             horizontalalignment='center',
             rotation='vertical',
             fontsize=boxplot_settings['fontsize'])
    fig.subplots_adjust(hspace=0.05, wspace=0.05)

    output_file = boxplot_settings[plot_variable]['output_file']
    fig.savefig(output_file, bbox_inches="tight")
    print "Saved %s" % output_file


# Also plot a more general overview of performance across each file system.

# In[26]:

fig = plt.figure(figsize=(8,6))
ax = fig.add_subplot(111)
df_concat.boxplot(
    column=[plot_variable],
    by=["darshan_file_system"],
    ax=ax,
    widths=0.75,
    boxprops={'linewidth':2},
    medianprops={'linewidth':2 },
    whiskerprops={'linewidth':2},
    capprops={'linewidth':2},
    flierprops={'linewidth':2},
    whis=[5,95])
### add window dressing to plots
# plt.xticks(rotation=45)
fig.suptitle("")
ax.set_title("", fontsize=14 )
ax.set_xlabel("")
ax.set_ylabel(y_label)
ax.xaxis.grid(False)

output_file = "perf-boxplots-fs.pdf"
fig.savefig(output_file, bbox_inches="tight")
print "Saved %s" % output_file


# Also create a boxplot of the coverage factor to demonstrate how often jobs were impacted by other jobs

# In[27]:

fig = plt.figure(figsize=(8,6))
ax = fig.add_subplot(111)
df_concat.boxplot(
    column=['coverage_factor'],
    by=["darshan_file_system"],
    ax=ax,
    widths=0.75,
    boxprops={'linewidth':2},
    medianprops={'linewidth':2 },
    whiskerprops={'linewidth':2},
    capprops={'linewidth':2},
    flierprops={'linewidth':2},
    whis=[5,95])
### add window dressing to plots
# plt.xticks(rotation=45)
fig.suptitle("")
ax.set_title("", fontsize=14 )
ax.set_xlabel("")
ax.set_ylabel("Coverage Factor")
ax.xaxis.grid(False)

output_file = "cf-boxplots-fs.pdf"
fig.savefig(output_file, bbox_inches="tight")
print "Saved %s" % output_file


# Also try a coverage factor histogram since boxplots don't represent the long tail very well.

# In[28]:

fig = plt.figure(figsize=(8,6))
ax = fig.add_subplot(111)

x = []
labels = []
for fs in df_concat['darshan_file_system'].unique():
    x.append(df_concat[df_concat["darshan_file_system"]==fs]["coverage_factor"].reset_index(drop=True).dropna())
    labels.append(fs) # in case the .unique() generator is nondeterministic
    
### retain the histogram results
histogram = ax.hist(x,
        bins=[0.101 * x for x in range(0,13)],
        label=labels,
        stacked=True
    )
# ax.yaxis.grid()
ax.legend()
ax.set_title("", fontsize=14 )
ax.set_xlabel("Coverage Factor")
ax.set_ylabel("Frequency")
fig.suptitle("")

output_file = "cf-histogram-fs.pdf"
fig.savefig(output_file, bbox_inches="tight")
print "Saved %s" % output_file


# Calculate the cumulative distribution function (CDF) from the histogram data to get a probability distribution of observing a given coverage factor (CF).

# In[29]:

for i in range(len(histogram[0])): # 4
    sums = [0 for x in range(len(histogram[0][i]))]
    for j in range(len(histogram[0][i])): # 13
        sums[j] += histogram[0][i][j]
probabilities = sums / sum(sums)
cumul = 0.0
print "%5s %6s %10s %10s" % ("CF", "Value", "CDF", "1-CDF")
for idx, probability in enumerate(probabilities):
    cumul += probability
    print "%5.3f %6.4f %10.4f %10.4f" % ( histogram[1][idx], probability, cumul, 1.0 - cumul )


# ## Cumulative Distribution Functions
# 
# We now have a distribution for the coverage factor and performance.  What is the probability of getting anywhere near peak performance?  How does this vary with the coverage factor?
# 
# First calculate the cumulative distribution function for keys of interest:

# In[30]:

def calculate_cdf( values ):
    """Create a pandas.Series that is the CDF of a list-like object"""

    denom = len(values) - 1
    x = sorted(values / values.max())
    y = [ i / denom for i in np.arange(len(x), dtype=np.float64) ]
    return pandas.Series( y, index=x )


# In[31]:

### Calculate CDFs for (1) each file system and (2) performance and coverage factor
cdfs = {}
for fs in _FILE_SYSTEM_ORDER:
    df_fs = df_concat[df_concat['darshan_file_system'] == fs]
    for cdf_key in 'darshan_normalized_perf_by_max', 'coverage_factor':
        if cdf_key not in cdfs:
            cdfs[cdf_key] = {}
        cdf = calculate_cdf(df_fs[cdf_key])
        cdfs[cdf_key][fs] = {
            'dependent_variable': cdf.values,
            'probability': cdf.index,
        }


# In[32]:

### don't use counter_labels because the context is slightly different
cdf_labels = {
    'darshan_normalized_perf_by_max': "Fraction Peak Performance",
    'coverage_factor': "Coverage Factor",
}
cdf_file_labels = {
    'darshan_normalized_perf_by_max': "perf",
    'coverage_factor': "coverage-factor",
}


# In[33]:

### Plot CDF side-by-side

fig, axes = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)
fig.set_size_inches(8,5)

for fs in _FILE_SYSTEM_ORDER:
    for idx, cdf_key in enumerate(sorted(cdfs.keys())):
        axes[idx].plot(
                       cdfs[cdf_key][fs]['dependent_variable'],
                       cdfs[cdf_key][fs]['probability'],
                       label=fs,
                       linewidth=2)
        axes[idx].set_xlabel(wrap(cdf_labels[cdf_key]), fontsize=14)
        axes[idx].set_ylabel("")
        axes[idx].plot([0.0, 1.0],[0.5, 0.5], '--', linewidth=2.0, color='red')
        axes[idx].legend().remove()
        axes[idx].set_xticks([0.0, 0.25, 0.50, 0.75, 1.0])
        for tick in axes[idx].xaxis.get_major_ticks():
            tick.label.set_fontsize(16) 
        for tick in axes[idx].yaxis.get_major_ticks():
            tick.label.set_fontsize(16)
            
axes[1].xaxis.get_major_ticks()[0].set_visible(False)
axes[0].set_title('(a)', position=(0.90,0.0), fontsize=24)
axes[1].set_title('(b)', position=(0.90,0.0), fontsize=24)
fig.legend( *(axes[0].get_legend_handles_labels()),
    fontsize=14,
               ncol=4,
               mode="expand",
               bbox_to_anchor=(0.11, 0.0, 0.79, 1.0),
               loc="upper left",
              borderaxespad=0.0)
axes[0].set_ylabel("Cumulative Probability", fontsize=14)
for i in 0, 1:
    axes[i].set_ylim([0.0, 1.0])
    axes[i].set_xlim([0.0, 1.0])
    axes[i].grid(True)
    axes[i].yaxis.set_ticks([0.0,0.25,0.50,0.75,1.0])
fig.suptitle("")
# fig.text(0.0, 0.5, "Cumulative Probability", va='center', rotation='vertical')
fig.subplots_adjust(hspace=0.0, wspace=0.0)

output_file = "cdf-both.pdf"
fig.savefig(output_file, bbox_inches="tight")
print "Saved %s" % output_file


# In[ ]:



