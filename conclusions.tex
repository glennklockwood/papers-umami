\section{Conclusions} \label{sec:conclusions}

By integrating data captured with existing tools from applications, storage systems, system health, and job scheduling, we demonstrated that holistically examining all components of the I/O subsystem is essential for understanding I/O performance variation.
We performed a month-long benchmarking study and characterized the I/O \emph{climate} on each system, then presented several case studies to demonstrate instances of abnormal I/O \emph{weather} and their effects on I/O performance.

Integrating metrics into the UMAMI diagram revealed that contention with other I/O workloads for storage system bandwidth, metadata op rates, and storage capacity can, but do not always, impact performance.
No single metric predicts I/O performance across HPC platforms;
the most significant metrics depend on systems' architecture, configuration, workload characteristics, and health, while 
factors such as job radius and $\textit{CF}_{\textit{nodehrs}}$ do not capture enough detail to indicate performance loss.
These findings provide a basis for improving monitoring tools to capture more detailed metrics that can better predict I/O performance.

% The importance of historical performance data in performance analysis also motivates the need for automated classification of jobs based on similar I/O motifs.
% With clustering or similar methods, generating UMAMI diagrams should be easily automated in production environments and made portable across diverse HPC platforms and centers.
